# -*- coding: utf-8 -*-
"""ML_Training_Nov8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wq5skHnRG8QPSSqB1BOm6qxAPi-6Uivq

# **ML Training: 7-Step ML Lifecycle Overview**

**Step 1: Business Understanding**

**Goal:** Understand the problem you are trying to solve.

**Example:** Let's say the business goal is to predict the type of iris flower based on its measurements.

1. Classify flowers (Logistic Regression)
2. Predict a continuous feature like petal length (Linear Regression).

**Step 2: Data Mining**

**Goal:** Gather data from multiple sources and identify potential features.

**Example**: The Iris dataset contains 4 features (sepal length, sepal width, petal length, and petal width) and 3 species (Setosa, Versicolor, Virginica).

The dataset is already available from *scikit-learn* for simplicity.
"""

# Step 1: Data Mining (Loading the data)
from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
X = iris.data  # Features
y = iris.target  # Target labels (species)

# Step 2: View the dataset
import pandas as pd

# Convert the Iris dataset into a DataFrame for easier visualization
df = pd.DataFrame(X, columns=iris.feature_names)

# Show the first few rows of the dataset
print("Dataset Preview:")
print(df.head())  # Display the first 5 rows

# Add the target (species) column to the DataFrame
df['species'] = iris.target
print(df.head())

# Display basic summary of the dataset
print("\nDataset Info:")
print(df.info())  # Information about data types and non-null counts

"""**Step 3: Data Cleaning**

**Goal:** Handle missing data, correct errors, and format data for model use.

**Example:** Our Iris dataset is already clean, so no missing data to handle. However, in a real-world scenario, you might have to fill or drop missing values.
"""

# Step 3: Data Cleaning (If any missing data)
import numpy as np

# Step 3: Data Cleaning (Check for missing values, duplicates, and other issues)

# Display the number of rows and columns in the dataset
print("Number of rows and columns in the dataset:")
print(df.shape)  # (rows, columns)

# Check for missing values
print("Missing Values in each column:")
print(df.isnull().sum())  # Count of missing values in each column

# Check for duplicates in the dataset
print("\nNumber of duplicate rows:")
print(df.duplicated().sum())  # Count of duplicate rows

# Check for any outliers (optional)
# For simplicity, let's just visualize the range of data
print("\nStatistical Summary of the Dataset:")
print(df.describe())  # Summary statistics like min, max, mean, etc.

# Checking for any inconsistent data (optional, e.g., negative values in features)
print("\nChecking for any negative values in the dataset:")
print((df < 0).sum())  # Count of negative values in each column (should be zero)

# Simulate missing data for demonstration (not in real Iris dataset)
import pandas as pd
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = y
# Simulating missing values in petal width (for demonstration)
df.iloc[0:10, 2] = np.nan  # Set some values as NaN (missing data)

# Check for missing values
print("Missing Values in each column:")
print(df.isnull().sum())

# Filling missing data with mean value (imputation)
df.fillna(df.mean(), inplace=True)

# Check for missing values
print("Missing Values in each column:")
print(df.isnull().sum())

"""**Step 4: Data Exploration**

**Goal: **Explore and visualize the data to understand distributions and patterns.

**Example:** Letâ€™s check the data distribution using some basic plots to understand relationships between features and target labels.
"""

# Step 4: Data Exploration (Visualizing the Data)
import seaborn as sns
import matplotlib.pyplot as plt

# Visualize the relationship between petal length and petal width
sns.scatterplot(x=df['petal length (cm)'], y=df['petal width (cm)'], hue=df['species'])
plt.title("Petal Length vs Petal Width")
plt.xlabel("Petal Length (cm)")
plt.ylabel("Petal Width (cm)")
plt.show()

"""**Step 5:** **Feature Engineering**

**Goal:** Transform the features to improve model performance. This could involve scaling, encoding, or creating new features.

**Example:** Standardization is a common technique to scale the data so that each feature has a mean of 0 and a standard deviation of 1.
"""

# Step 5: Feature Engineering (Scaling the features)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Apply scaling to the features

X_scaled

"""**Step 6: Predictive Modeling**

**Goal:** Train the machine learning models and use them to make predictions.
Linear Regression Example: We will predict a continuous variable (petal length) using Linear Regression.

**Logistic Regression Example:** We will predict the species of the flower using Logistic Regression.
"""

# Step 6: Predictive Modeling

# Linear Regression (predicting petal length as a continuous variable)
from sklearn.linear_model import LinearRegression

linear_model = LinearRegression()
linear_model.fit(X_scaled, iris.target)  # Target is now a continuous value (petal length prediction)
y_pred_linear = linear_model.predict(X_scaled)

# Logistic Regression (classifying species)
from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression(max_iter=200)
logistic_model.fit(X_scaled, y)  # Target is now the flower species
y_pred_logistic = logistic_model.predict(X_scaled)

"""**Step 7: Data Visualization**

**Goal:** Visualize model performance and make insights clear.

**For Linear Regression:** We will show how well the model predicts petal length.

**For Logistic Regression:** We will visualize the accuracy of the classification model.
"""

# Step 7: Data Visualization

# Visualization for Linear Regression (Petal Length Prediction)
plt.figure(figsize=(8, 6))
plt.scatter(range(len(y_pred_linear)), y_pred_linear, label='Predicted Petal Length', color='blue', alpha=0.6)
plt.scatter(range(len(iris.target)), iris.target, label='Actual Petal Length', color='red', alpha=0.6)
plt.title("Linear Regression: Petal Length Prediction")
plt.xlabel("Sample Index")
plt.ylabel("Petal Length (cm)")
plt.legend()
plt.show()

# Visualization for Logistic Regression (Species Classification)
sns.heatmap(pd.crosstab(y, y_pred_logistic), annot=True, fmt='d', cmap="Blues", xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.title("Logistic Regression: Species Classification")
plt.xlabel("Predicted Species")
plt.ylabel("Actual Species")
plt.show()

"""**Key Takeaways**

1. Linear Regression is used for predicting a continuous variable (e.g., petal length).

2. Logistic Regression is used for classifying categories (e.g., iris species).

3. Visualizing the predictions and actual values helps us understand how well the model is performing.
"""